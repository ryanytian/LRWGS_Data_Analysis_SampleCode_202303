{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bab5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function used on 'large_svs.vcf' files to extract all information as dictionaries ###\n",
    "\n",
    "'''\n",
    "Input: \n",
    "\n",
    "vcfreader (from the pyvcf library) of the file\n",
    "\n",
    "    - The vcfreader basically reads the vcf files line by line\n",
    "\n",
    "Outputs:\n",
    "\n",
    "1. temp_sv: all the large SVs marked as DEL, DUP, or INV regardless of filtering status from the vcf file\n",
    "2. temp_BND: all the large SVs marked as BND regardless of filtering status from the vcf file\n",
    "\n",
    "    - Note that the outputs exclude SVs marked with an UNK status\n",
    "    \n",
    "''' \n",
    "\n",
    "def extract_SV_info_wo_UNK(vcfreader):\n",
    "    \n",
    "    temp_SV = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "               'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "               'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "    \n",
    "    temp_BND = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                'SVTYPE': [], 'SVTYPE2': [], 'MATEID': [], 'QUAL': [], \\\n",
    "                'GT': [], 'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "    counter = 0\n",
    "    \n",
    "    for record in vcfreader:\n",
    "        \n",
    "        if str(record.INFO['SVTYPE']) == 'DEL' or str(record.INFO['SVTYPE']) == 'DUP' or \\\n",
    "        str(record.INFO['SVTYPE']) == 'INV':\n",
    "\n",
    "            temp_SV['CHROM'].append(record.CHROM)\n",
    "            temp_SV['POS'].append(record.POS)\n",
    "            temp_SV['ID'].append(record.ID)\n",
    "            temp_SV['REF'].append(record.REF)\n",
    "\n",
    "            if len(record.ALT) != 1:\n",
    "                print('ERROR')\n",
    "                print('ALT: ' + str(record.ALT))\n",
    "\n",
    "            temp_SV['ALT'].append(str(record.ALT[0]))\n",
    "            temp_SV['SVTYPE'].append(str(record.INFO['SVTYPE']))\n",
    "            temp_SV['QUAL'].append(record.QUAL)\n",
    "            temp_SV['END'].append(record.INFO['END'])\n",
    "            temp_SV['SVLEN'].append(record.INFO['SVLEN'])\n",
    "            temp_SV['GT'].append(str(record.samples[0]['GT']))\n",
    "            temp_SV['HAP_ALLELIC_FRAC'].append(record.INFO['HAP_ALLELIC_FRAC'])\n",
    "            temp_SV['ALLELIC_FRAC'].append(record.INFO['ALLELIC_FRAC'])\n",
    "            temp_SV['FILTER'].append(record.FILTER)\n",
    "\n",
    "        elif str(record.INFO['SVTYPE']) == 'BND':\n",
    "            \n",
    "            temp_BND['CHROM'].append(record.CHROM)\n",
    "            temp_BND['POS'].append(record.POS)\n",
    "            temp_BND['ID'].append(record.ID)\n",
    "            temp_BND['REF'].append(record.REF)\n",
    "\n",
    "            if len(record.ALT) != 1:\n",
    "                print('ERROR')\n",
    "                print('ALT: ' + str(record.ALT))\n",
    "\n",
    "            temp_BND['ALT'].append(str(record.ALT[0]))\n",
    "            temp_BND['SVTYPE'].append(str(record.INFO['SVTYPE']))\n",
    "            temp_BND['SVTYPE2'].append(str(record.INFO['SVTYPE2']))\n",
    "            temp_BND['MATEID'].append(str(record.INFO['MATEID']))                    \n",
    "            temp_BND['QUAL'].append(record.QUAL)\n",
    "            temp_BND['GT'].append(str(record.samples[0]['GT']))\n",
    "            temp_BND['HAP_ALLELIC_FRAC'].append(record.INFO['HAP_ALLELIC_FRAC'])\n",
    "            temp_BND['ALLELIC_FRAC'].append(record.INFO['ALLELIC_FRAC'])\n",
    "            temp_BND['FILTER'].append(record.FILTER)\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "    return temp_SV, temp_BND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaff92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Debugging function, prints all contents from the SV dictionary line by line ###\n",
    "\n",
    "def debug_sv(sv_dict):\n",
    "    \n",
    "    for i in range(len(sv_dict['CHROM'])):\n",
    "        \n",
    "        print('index: ' + str(i))\n",
    "        print('CHROM: ' + str(sv_dict['CHROM'][i]))\n",
    "        print('POS: ' + str(sv_dict['POS'][i]))\n",
    "        print('ID: ' + str(sv_dict['ID'][i]))\n",
    "        print('REF: ' + str(sv_dict['REF'][i]))\n",
    "        print('ALT: ' + str(sv_dict['ALT'][i]))\n",
    "        print('SVTYPE: ' + str(sv_dict['SVTYPE'][i]))\n",
    "        print('QUAL: ' + str(sv_dict['QUAL'][i]))\n",
    "        print('END: ' + str(sv_dict['END'][i]))\n",
    "        print('SVLEN: ' + str(sv_dict['SVLEN'][i]))\n",
    "        print('GT: ' + str(sv_dict['GT'][i]))\n",
    "        print('HAP_ALLELIC_FRAC: ' + str(sv_dict['HAP_ALLELIC_FRAC'][i]))\n",
    "        print('ALLELIC_FRAC: ' + str(sv_dict['ALLELIC_FRAC'][i]))\n",
    "        print('FILTER: ' + str(sv_dict['FILTER'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5721804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function used on 'dels.vcf' files to extract all information as dictionaries ###\n",
    "\n",
    "'''\n",
    "Input: \n",
    "\n",
    "vcfreader (from the pyvcf library) of the file\n",
    "\n",
    "    - The vcfreader basically reads the vcf files line by line\n",
    "\n",
    "Outputs:\n",
    "\n",
    "1. temp_del: all the small dels regardless of filtering status from the vcf file\n",
    "2. temp_BND: all the dels marked as BND regardless of filtering status from the vcf file\n",
    "\n",
    "    - Note that the outputs exclude SVs marked with an UNK status\n",
    "    \n",
    "''' \n",
    "\n",
    "\n",
    "def extract_small_del_info(vcfreader):\n",
    "    \n",
    "    temp_del = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "    \n",
    "    temp_BND = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                'SVTYPE': [], 'SVTYPE2': [], 'MATEID': [], 'QUAL': [], \\\n",
    "                'GT': [], 'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "   \n",
    "    counter = 0\n",
    "    \n",
    "    for record in vcfreader:\n",
    "        \n",
    "        if str(record.INFO['SVTYPE']) == 'DEL':\n",
    "\n",
    "            temp_del['CHROM'].append(record.CHROM)\n",
    "            temp_del['POS'].append(record.POS)\n",
    "            temp_del['ID'].append(record.ID)\n",
    "            temp_del['REF'].append(record.REF)\n",
    "\n",
    "            if len(record.ALT) != 1:\n",
    "                print('ERROR')\n",
    "                print('ALT: ' + str(record.ALT))\n",
    "\n",
    "            temp_del['ALT'].append(str(record.ALT[0]))\n",
    "            temp_del['SVTYPE'].append(str(record.INFO['SVTYPE']))\n",
    "            temp_del['QUAL'].append(record.QUAL)\n",
    "            temp_del['END'].append(record.INFO['END'])\n",
    "            temp_del['SVLEN'].append(record.INFO['SVLEN'])\n",
    "            temp_del['GT'].append(str(record.samples[0]['GT']))\n",
    "            temp_del['HAP_ALLELIC_FRAC'].append(record.INFO['HAP_ALLELIC_FRAC'])\n",
    "            temp_del['ALLELIC_FRAC'].append(record.INFO['ALLELIC_FRAC'])\n",
    "            temp_del['FILTER'].append(record.FILTER)\n",
    "\n",
    "        elif str(record.INFO['SVTYPE']) == 'BND':\n",
    "            \n",
    "            temp_BND['CHROM'].append(record.CHROM)\n",
    "            temp_BND['POS'].append(record.POS)\n",
    "            temp_BND['ID'].append(record.ID)\n",
    "            temp_BND['REF'].append(record.REF)\n",
    "\n",
    "            if len(record.ALT) != 1:\n",
    "                print('ERROR')\n",
    "                print('ALT: ' + str(record.ALT))\n",
    "\n",
    "            temp_BND['ALT'].append(str(record.ALT[0]))\n",
    "            temp_BND['SVTYPE'].append(str(record.INFO['SVTYPE']))\n",
    "            temp_BND['SVTYPE2'].append(str(record.INFO['SVTYPE2']))\n",
    "            temp_BND['MATEID'].append(str(record.INFO['MATEID']))                    \n",
    "            temp_BND['QUAL'].append(record.QUAL)\n",
    "            temp_BND['GT'].append(str(record.samples[0]['GT']))\n",
    "            temp_BND['HAP_ALLELIC_FRAC'].append(record.INFO['HAP_ALLELIC_FRAC'])\n",
    "            temp_BND['ALLELIC_FRAC'].append(record.INFO['ALLELIC_FRAC'])\n",
    "            temp_BND['FILTER'].append(record.FILTER)\n",
    "        \n",
    "        else:\n",
    "            print('ERROR')\n",
    "            print(str(record.INFO['SVTYPE']))\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    return temp_del, temp_BND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf3e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function used on SV dictionaries to pick out SVs tagged with Long Ranger's built-in filters ###\n",
    "\n",
    "## len(dict['FILTER'][i]) == 0 indicates that there are no tag on the SV\n",
    "## SVs without any tag are SVs that passed all built-in filters from Long Ranger\n",
    "\n",
    "def split_sv_by_filter(sample_dict):\n",
    "        \n",
    "    sample_filter_pass = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                          'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                          'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "\n",
    "    sample_filter_fail = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                          'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                          'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "\n",
    "    for i in range(len(sample_dict['CHROM'])):\n",
    "        \n",
    "        if len(sample_dict['FILTER'][i]) == 0:\n",
    "            \n",
    "            sample_filter_pass['CHROM'].append(sample_dict['CHROM'][i])\n",
    "            sample_filter_pass['POS'].append(sample_dict['POS'][i])\n",
    "            sample_filter_pass['ID'].append(sample_dict['ID'][i])\n",
    "            sample_filter_pass['REF'].append(sample_dict['REF'][i])\n",
    "            sample_filter_pass['ALT'].append(sample_dict['ALT'][i])\n",
    "            sample_filter_pass['SVTYPE'].append(sample_dict['SVTYPE'][i])\n",
    "            sample_filter_pass['QUAL'].append(sample_dict['QUAL'][i])\n",
    "            sample_filter_pass['END'].append(sample_dict['END'][i])\n",
    "            sample_filter_pass['SVLEN'].append(sample_dict['SVLEN'][i])\n",
    "            sample_filter_pass['GT'].append(sample_dict['GT'][i])\n",
    "            sample_filter_pass['HAP_ALLELIC_FRAC'].append(sample_dict['HAP_ALLELIC_FRAC'][i])\n",
    "            sample_filter_pass['ALLELIC_FRAC'].append(sample_dict['ALLELIC_FRAC'][i])\n",
    "            sample_filter_pass['FILTER'].append(sample_dict['FILTER'][i])\n",
    "\n",
    "        else:\n",
    "\n",
    "            sample_filter_fail['CHROM'].append(sample_dict['CHROM'][i])\n",
    "            sample_filter_fail['POS'].append(sample_dict['POS'][i])\n",
    "            sample_filter_fail['ID'].append(sample_dict['ID'][i])\n",
    "            sample_filter_fail['REF'].append(sample_dict['REF'][i])\n",
    "            sample_filter_fail['ALT'].append(sample_dict['ALT'][i])\n",
    "            sample_filter_fail['SVTYPE'].append(sample_dict['SVTYPE'][i])\n",
    "            sample_filter_fail['QUAL'].append(sample_dict['QUAL'][i])\n",
    "            sample_filter_fail['END'].append(sample_dict['END'][i])\n",
    "            sample_filter_fail['SVLEN'].append(sample_dict['SVLEN'][i])\n",
    "            sample_filter_fail['GT'].append(sample_dict['GT'][i])\n",
    "            sample_filter_fail['HAP_ALLELIC_FRAC'].append(sample_dict['HAP_ALLELIC_FRAC'][i])\n",
    "            sample_filter_fail['ALLELIC_FRAC'].append(sample_dict['ALLELIC_FRAC'][i])\n",
    "            sample_filter_fail['FILTER'].append(sample_dict['FILTER'][i])\n",
    "            \n",
    "\n",
    "    return sample_filter_pass, sample_filter_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42cd4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to reconcile BNDs on the same chromosome and with only 1 MATEID to their appropriate SV types ###\n",
    "\n",
    "def combine_BNDs_on_same_chr(BND_dict):\n",
    "    \n",
    "    output_dict = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                   'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                   'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "\n",
    "    temp_df = pd.DataFrame.from_dict(BND_dict)\n",
    "    \n",
    "    for ind, row in temp_df.iterrows():\n",
    "        \n",
    "        # If the call ID is the first half of the BND pairs\n",
    "        if row['ID'][-1] == '1':\n",
    "            \n",
    "            # Note that the MATEID column is encoded in the format of ['call_3160_2'], thus the [2:-2]\n",
    "            temp_row = temp_df[temp_df['ID'] == row['MATEID'][2:-2]]\n",
    "\n",
    "            if len(temp_row) == 0:\n",
    "                pass\n",
    "            \n",
    "            elif row['SVTYPE2'] == 'BND':\n",
    "                pass\n",
    "            \n",
    "            # If the second half of the pair is on the same chromosome\n",
    "            elif temp_row['CHROM'].tolist()[0] == row['CHROM']:\n",
    "                \n",
    "                output_dict['CHROM'].append(row['CHROM'])\n",
    "                output_dict['POS'].append(row['POS'])\n",
    "                output_dict['ID'].append(row['ID'][:-2])\n",
    "                output_dict['REF'].append(row['REF'])\n",
    "                output_dict['ALT'].append('<' + row['SVTYPE2'] + '>')\n",
    "                output_dict['SVTYPE'].append(row['SVTYPE2'])\n",
    "                output_dict['QUAL'].append(row['QUAL'])\n",
    "                output_dict['END'].append(temp_row['POS'].tolist()[0])\n",
    "                \n",
    "                if row['SVTYPE2'] == 'DEL':\n",
    "                    output_dict['SVLEN'].append(row['POS'] - temp_row['POS'].tolist()[0])\n",
    "                else:\n",
    "                    output_dict['SVLEN'].append(temp_row['POS'].tolist()[0] - row['POS'])\n",
    "                \n",
    "                output_dict['GT'].append(row['GT'])\n",
    "                output_dict['HAP_ALLELIC_FRAC'].append(row['HAP_ALLELIC_FRAC'])\n",
    "                output_dict['ALLELIC_FRAC'].append(row['ALLELIC_FRAC'])\n",
    "                output_dict['FILTER'].append(temp_row['FILTER'].tolist()[0] + row['FILTER'])\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a18efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility function for sorting of variable IDs into bins with corresponding patient IDs ###\n",
    "\n",
    "def sort_sample_by_patient_and_type(patients, var_name_list):\n",
    "    \n",
    "    sample_dict = {}\n",
    "\n",
    "    for p in patients:\n",
    "\n",
    "        sample_dict[p] = {'NORM': [], 'TUMOUR': []}\n",
    "        p_sample = [i for i in var_name_list if i.startswith(p)]\n",
    "\n",
    "        for s in p_sample:\n",
    "\n",
    "            if 'norm' in s:\n",
    "\n",
    "                sample_dict[p]['NORM'].append(s)\n",
    "\n",
    "            else: \n",
    "\n",
    "                sample_dict[p]['TUMOUR'].append(s)\n",
    "                \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to split SV dictionaries into type-specific dictionaries ###\n",
    "\n",
    "def split_DEL_INV_DUP(combined_svs):\n",
    "    \n",
    "    temp_DEL = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "    \n",
    "    temp_INV = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "    \n",
    "    temp_DUP = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': []}\n",
    "    \n",
    "    for i in range(len(combined_svs['CHROM'])):\n",
    "        \n",
    "        if combined_svs['SVTYPE'][i] == 'DEL':\n",
    "        \n",
    "            temp_DEL['CHROM'].append(combined_svs['CHROM'][i])\n",
    "            temp_DEL['POS'].append(combined_svs['POS'][i])\n",
    "            temp_DEL['ID'].append(combined_svs['ID'][i])\n",
    "            temp_DEL['REF'].append(combined_svs['REF'][i])\n",
    "            temp_DEL['ALT'].append(combined_svs['ALT'][i])\n",
    "            temp_DEL['SVTYPE'].append(combined_svs['SVTYPE'][i])\n",
    "            temp_DEL['QUAL'].append(combined_svs['QUAL'][i])\n",
    "            temp_DEL['END'].append(combined_svs['END'][i])\n",
    "            temp_DEL['SVLEN'].append(combined_svs['SVLEN'][i])\n",
    "            temp_DEL['GT'].append(combined_svs['GT'][i])\n",
    "            temp_DEL['HAP_ALLELIC_FRAC'].append(combined_svs['HAP_ALLELIC_FRAC'][i])\n",
    "            temp_DEL['ALLELIC_FRAC'].append(combined_svs['ALLELIC_FRAC'][i])\n",
    "            temp_DEL['FILTER'].append(combined_svs['FILTER'][i])\n",
    "        \n",
    "        if combined_svs['SVTYPE'][i] == 'INV':\n",
    "        \n",
    "            temp_INV['CHROM'].append(combined_svs['CHROM'][i])\n",
    "            temp_INV['POS'].append(combined_svs['POS'][i])\n",
    "            temp_INV['ID'].append(combined_svs['ID'][i])\n",
    "            temp_INV['REF'].append(combined_svs['REF'][i])\n",
    "            temp_INV['ALT'].append(combined_svs['ALT'][i])\n",
    "            temp_INV['SVTYPE'].append(combined_svs['SVTYPE'][i])\n",
    "            temp_INV['QUAL'].append(combined_svs['QUAL'][i])\n",
    "            temp_INV['END'].append(combined_svs['END'][i])\n",
    "            temp_INV['SVLEN'].append(combined_svs['SVLEN'][i])\n",
    "            temp_INV['GT'].append(combined_svs['GT'][i])\n",
    "            temp_INV['HAP_ALLELIC_FRAC'].append(combined_svs['HAP_ALLELIC_FRAC'][i])\n",
    "            temp_INV['ALLELIC_FRAC'].append(combined_svs['ALLELIC_FRAC'][i])\n",
    "            temp_INV['FILTER'].append(combined_svs['FILTER'][i])\n",
    "        \n",
    "        if combined_svs['SVTYPE'][i] == 'DUP':\n",
    "        \n",
    "            temp_DUP['CHROM'].append(combined_svs['CHROM'][i])\n",
    "            temp_DUP['POS'].append(combined_svs['POS'][i])\n",
    "            temp_DUP['ID'].append(combined_svs['ID'][i])\n",
    "            temp_DUP['REF'].append(combined_svs['REF'][i])\n",
    "            temp_DUP['ALT'].append(combined_svs['ALT'][i])\n",
    "            temp_DUP['SVTYPE'].append(combined_svs['SVTYPE'][i])\n",
    "            temp_DUP['QUAL'].append(combined_svs['QUAL'][i])\n",
    "            temp_DUP['END'].append(combined_svs['END'][i])\n",
    "            temp_DUP['SVLEN'].append(combined_svs['SVLEN'][i])\n",
    "            temp_DUP['GT'].append(combined_svs['GT'][i])\n",
    "            temp_DUP['HAP_ALLELIC_FRAC'].append(combined_svs['HAP_ALLELIC_FRAC'][i])\n",
    "            temp_DUP['ALLELIC_FRAC'].append(combined_svs['ALLELIC_FRAC'][i])\n",
    "            temp_DUP['FILTER'].append(combined_svs['FILTER'][i])\n",
    "        \n",
    "    return temp_DEL, temp_INV, temp_DUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab46e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility function given an array and a value ###\n",
    "### find the elements in the array that are the closest to the value ###\n",
    "### returns the element and the array of indices of the elements ###\n",
    "\n",
    "def find_nearest(array, value):\n",
    "\n",
    "    array = np.asarray(array)\n",
    "    dif_array = np.abs(array - value)\n",
    "    idx_array = np.where(dif_array == dif_array.min())[0]\n",
    "    \n",
    "    return array[idx_array[0]], idx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0c1134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, array([2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest([1, 2, 6, 4, 6], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "921f2864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest([1, 2, 6, 5, 4, 6], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f04c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that computes the distance of each tumour SV to their closest counterparts in the normal sample ###\n",
    "\n",
    "### Note that the function only focuses on the starting position (POS) to look for the closest counterpart ###\n",
    "\n",
    "'''\n",
    "Input: \n",
    "\n",
    "1. sv_normal_dict: dictionary of SVs from the normal sample\n",
    "2. sv_tumour_dict: dictionary of SVs from the tumour sample\n",
    "\n",
    "Outputs:\n",
    "\n",
    "output_dict = {'NEAREST_POS':[], 'NEAREST_POS_DIST':[], \\\n",
    "               'NEAREST_END':[], 'NEAREST_END_DIST':[], \\\n",
    "               'NEAREST_TOTAL_DIST':[], 'NEAREST_NORMAL_IDX':[]}\n",
    "- NEAREST_POS: where on the chromosome the nearest POS (start of SV) is in the normal sample\n",
    "- NEAREST_POS_DIST: the absolute difference between the tumour SV POS and the nearest normal SV POS\n",
    "- NEAREST_END: where on the chromosome the nearest END (end of SV) is in the normal sample\n",
    "- NEAREST_END_DIST: the absolute difference between the tumour SV END and the nearest normal SV END\n",
    "- NEAREST_TOTAL_DIST: NEAREST_POS_DIST + NEAREST_END_DIST\n",
    "- NEAREST_NORMAL_IDX: index of the nearest SV from the normal dictionary\n",
    "\n",
    "'''\n",
    "\n",
    "def get_sv_distance_by_start(sv_normal_dict, sv_tumour_dict):\n",
    "    \n",
    "    output_dict = {'NEAREST_POS':[], 'NEAREST_POS_DIST':[], \\\n",
    "                   'NEAREST_END':[], 'NEAREST_END_DIST':[], \\\n",
    "                   'NEAREST_TOTAL_DIST':[], 'NEAREST_NORMAL_IDX':[]}\n",
    "    \n",
    "    for i in range(len(sv_tumour_dict['CHROM'])):\n",
    "        \n",
    "        # Get index array for elements with the same chromosome\n",
    "        temp_normal_idx_array_w_chrom = \\\n",
    "        np.where(np.array(sv_normal_dict['CHROM']) == np.array(sv_tumour_dict['CHROM'][i]))\n",
    "        \n",
    "        if temp_normal_idx_array_w_chrom[0].shape[0] == 0:\n",
    "            \n",
    "            output_dict['NEAREST_POS'].append('N/A')\n",
    "            output_dict['NEAREST_POS_DIST'].append('N/A')\n",
    "            output_dict['NEAREST_END'].append('N/A')\n",
    "            output_dict['NEAREST_END_DIST'].append('N/A')\n",
    "            output_dict['NEAREST_TOTAL_DIST'].append('N/A')\n",
    "            output_dict['NEAREST_NORMAL_IDX'].append('N/A')\n",
    "\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            # Find POS with smallest distance\n",
    "            \n",
    "            temp_normal_pos_array_w_chrom = np.array(sv_normal_dict['POS'])[temp_normal_idx_array_w_chrom]\n",
    "            \n",
    "            temp_closest_pos, temp_idx_array = find_nearest(temp_normal_pos_array_w_chrom, sv_tumour_dict['POS'][i])\n",
    "            \n",
    "            \n",
    "            # Find END with smallest distance (subset of earlier indices)\n",
    "            \n",
    "            temp_normal_end_array_w_chrom = np.array(sv_normal_dict['END'])[temp_normal_idx_array_w_chrom]\n",
    "            \n",
    "            temp_closest_end, temp_idx_end = find_nearest(temp_normal_end_array_w_chrom[temp_idx_array], \\\n",
    "                                                          sv_tumour_dict['END'][i])\n",
    "\n",
    "            temp_normal_idx = temp_normal_idx_array_w_chrom[0][temp_idx_array[temp_idx_end[0]]]\n",
    "            \n",
    "            \n",
    "            # Debug\n",
    "            \n",
    "            if abs(temp_closest_pos - sv_tumour_dict['POS'][i]) != \\\n",
    "            abs(sv_normal_dict['POS'][temp_normal_idx] - sv_tumour_dict['POS'][i]):\n",
    "                \n",
    "                print('POS')\n",
    "                print(i)\n",
    "                print('CHROM: ' + sv_normal_dict['CHROM'][temp_normal_idx])\n",
    "                print('POS: ' + str(sv_normal_dict['POS'][temp_normal_idx]))\n",
    "                print('END: ' + str(sv_normal_dict['END'][temp_normal_idx]))\n",
    "                print(temp_normal_idx)\n",
    "                print('ERROR')\n",
    "\n",
    "            if abs(temp_closest_end - sv_tumour_dict['END'][i]) != \\\n",
    "            abs(sv_normal_dict['END'][temp_normal_idx] - sv_tumour_dict['END'][i]):\n",
    "                \n",
    "                print('END')\n",
    "                print(i)\n",
    "                print('CHROM: ' + sv_normal_dict['CHROM'][temp_normal_idx])\n",
    "                print('POS: ' + str(sv_normal_dict['POS'][temp_normal_idx]))\n",
    "                print('END: ' + str(sv_normal_dict['END'][temp_normal_idx]))\n",
    "                print('normal_idx: ' + temp_normal_idx)\n",
    "                print('ERROR')\n",
    "\n",
    "            output_dict['NEAREST_POS'].append(temp_closest_pos)\n",
    "            output_dict['NEAREST_POS_DIST'].append(abs(temp_closest_pos - sv_tumour_dict['POS'][i]))\n",
    "            output_dict['NEAREST_END'].append(temp_closest_end)\n",
    "            output_dict['NEAREST_END_DIST'].append(abs(temp_closest_end - sv_tumour_dict['END'][i]))\n",
    "            output_dict['NEAREST_TOTAL_DIST'].append(abs(temp_closest_pos - sv_tumour_dict['POS'][i]) + \\\n",
    "                                                    abs(temp_closest_end - sv_tumour_dict['END'][i]))\n",
    "            output_dict['NEAREST_NORMAL_IDX'].append(temp_normal_idx)\n",
    "            \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f6791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that splits the tumour SVs into somatic SVs and germline SVs using get_sv_distance_by_start ###\n",
    "\n",
    "def somatic_sv_call_by_nearest_normal(normal_filter_pass, sample_filter_pass, dist_cutoff):\n",
    "    \n",
    "    somatic_dict = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                    'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                    'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': [], 'DIST': []}\n",
    "    \n",
    "    germline_dict = {'CHROM': [], 'POS': [], 'ID': [], 'REF': [], 'ALT': [], \\\n",
    "                     'SVTYPE': [], 'QUAL': [], 'END': [], 'SVLEN': [], 'GT': [], \\\n",
    "                     'HAP_ALLELIC_FRAC': [], 'ALLELIC_FRAC': [], 'FILTER': [], 'DIST': []}\n",
    "    \n",
    "    dist_dict = get_sv_distance_by_start(normal_filter_pass, sample_filter_pass)\n",
    "    \n",
    "    if len(dist_dict['NEAREST_TOTAL_DIST']) != len(sample_filter_pass['CHROM']):\n",
    "        \n",
    "        print('ERROR, SKIPPING SAMPLES WHEN CALCULATING DISTANCES.')\n",
    "    \n",
    "    for i in range(len(dist_dict['NEAREST_POS'])):\n",
    "                \n",
    "        if dist_dict['NEAREST_TOTAL_DIST'][i] == 'N/A':\n",
    "            \n",
    "            somatic_dict['CHROM'].append(sample_filter_pass['CHROM'][i])\n",
    "            somatic_dict['POS'].append(sample_filter_pass['POS'][i])\n",
    "            somatic_dict['ID'].append(sample_filter_pass['ID'][i])\n",
    "            somatic_dict['REF'].append(sample_filter_pass['REF'][i])\n",
    "            somatic_dict['ALT'].append(sample_filter_pass['ALT'][i])\n",
    "            somatic_dict['SVTYPE'].append(sample_filter_pass['SVTYPE'][i])\n",
    "            somatic_dict['QUAL'].append(sample_filter_pass['QUAL'][i])\n",
    "            somatic_dict['END'].append(sample_filter_pass['END'][i])\n",
    "            somatic_dict['SVLEN'].append(sample_filter_pass['SVLEN'][i])\n",
    "            somatic_dict['GT'].append(sample_filter_pass['GT'][i])\n",
    "            somatic_dict['HAP_ALLELIC_FRAC'].append(sample_filter_pass['HAP_ALLELIC_FRAC'][i])\n",
    "            somatic_dict['ALLELIC_FRAC'].append(sample_filter_pass['ALLELIC_FRAC'][i])\n",
    "            somatic_dict['FILTER'].append(sample_filter_pass['FILTER'][i])\n",
    "            somatic_dict['DIST'].append('N/A')\n",
    "\n",
    "        elif dist_dict['NEAREST_TOTAL_DIST'][i] > dist_cutoff:\n",
    "            \n",
    "            somatic_dict['CHROM'].append(sample_filter_pass['CHROM'][i])\n",
    "            somatic_dict['POS'].append(sample_filter_pass['POS'][i])\n",
    "            somatic_dict['ID'].append(sample_filter_pass['ID'][i])\n",
    "            somatic_dict['REF'].append(sample_filter_pass['REF'][i])\n",
    "            somatic_dict['ALT'].append(sample_filter_pass['ALT'][i])\n",
    "            somatic_dict['SVTYPE'].append(sample_filter_pass['SVTYPE'][i])\n",
    "            somatic_dict['QUAL'].append(sample_filter_pass['QUAL'][i])\n",
    "            somatic_dict['END'].append(sample_filter_pass['END'][i])\n",
    "            somatic_dict['SVLEN'].append(sample_filter_pass['SVLEN'][i])\n",
    "            somatic_dict['GT'].append(sample_filter_pass['GT'][i])\n",
    "            somatic_dict['HAP_ALLELIC_FRAC'].append(sample_filter_pass['HAP_ALLELIC_FRAC'][i])\n",
    "            somatic_dict['ALLELIC_FRAC'].append(sample_filter_pass['ALLELIC_FRAC'][i])\n",
    "            somatic_dict['FILTER'].append(sample_filter_pass['FILTER'][i])\n",
    "            somatic_dict['DIST'].append(dist_dict['NEAREST_TOTAL_DIST'][i])\n",
    "\n",
    "        else:\n",
    "            \n",
    "            germline_dict['CHROM'].append(sample_filter_pass['CHROM'][i])\n",
    "            germline_dict['POS'].append(sample_filter_pass['POS'][i])\n",
    "            germline_dict['ID'].append(sample_filter_pass['ID'][i])\n",
    "            germline_dict['REF'].append(sample_filter_pass['REF'][i])\n",
    "            germline_dict['ALT'].append(sample_filter_pass['ALT'][i])\n",
    "            germline_dict['SVTYPE'].append(sample_filter_pass['SVTYPE'][i])\n",
    "            germline_dict['QUAL'].append(sample_filter_pass['QUAL'][i])\n",
    "            germline_dict['END'].append(sample_filter_pass['END'][i])\n",
    "            germline_dict['SVLEN'].append(sample_filter_pass['SVLEN'][i])\n",
    "            germline_dict['GT'].append(sample_filter_pass['GT'][i])\n",
    "            germline_dict['HAP_ALLELIC_FRAC'].append(sample_filter_pass['HAP_ALLELIC_FRAC'][i])\n",
    "            germline_dict['ALLELIC_FRAC'].append(sample_filter_pass['ALLELIC_FRAC'][i])\n",
    "            germline_dict['FILTER'].append(sample_filter_pass['FILTER'][i])\n",
    "            germline_dict['DIST'].append(dist_dict['NEAREST_TOTAL_DIST'][i])\n",
    "\n",
    "    return somatic_dict, germline_dict, dist_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
